# üîÑ Migration Guide: V1 ‚Üí V2

## Overview of Changes

### V1 (Original)
- ‚ùå Hardcoded "Jahresr√ºckblick" structure
- ‚ùå Manual JSON creation via Google Gem
- ‚ùå Manual image uploads
- ‚ùå Requires Mentimeter integration
- ‚ùå Fixed chapter structure

### V2 (Refactored)
- ‚úÖ Generic transcript-based generation
- ‚úÖ Automatic content creation with Gemini
- ‚úÖ Automatic image generation from Wikimedia
- ‚úÖ No external tools required
- ‚úÖ Flexible chapter structure

---

## Key Architectural Changes

### 1. Introduction Chapter

**V1**: Hardcoded template
```python
def create_hardcoded_introduction(roman_number: str):
    intro_html = f"""<h2><strong>Willkommen zum Jahresr√ºckblick 2025, Teil {roman_number}</strong></h2>
    <p>Gemeinsam blicken wir zur√ºck auf bewegende, spannende und teils tragische Ereignisse...</p>"""
```

**V2**: Dynamic generation from transcript
```python
def create_custom_introduction(intro_data: dict):
    # intro_data generated by Gemini based on transcript content
    # Includes: title, welcome_text, learning_objectives, workflow
```

**Migration**: No action needed - system generates appropriate introduction automatically

---

### 2. Memory Game

**V1**: Manual process
1. User creates JSON with image paths manually
2. User uploads images separately
3. Fixed to 4 cards via hardcoded setting

**V2**: Automated process
1. Gemini analyzes transcript ‚Üí generates 6 key concepts
2. System searches Wikimedia for images automatically
3. Creates text images for matching
4. Uses all generated pairs (dynamic)

**Migration**: 
- Remove manual image upload logic
- Remove Google Gem dependency for memory content
- System handles everything from transcript

---

### 3. Content Generation Flow

**V1**: Sequential manual JSON input
```
User ‚Üí Google Gem (manual) ‚Üí Copy JSON ‚Üí Paste to UI ‚Üí Upload images ‚Üí Generate
```

**V2**: Automated pipeline
```
User ‚Üí Paste transcript ‚Üí Click generate ‚Üí AI creates all content ‚Üí Download
```

**Migration**: Replace manual steps with single AI call per content type

---

## File-by-File Changes

### `orchestrator.py` ‚Üí `orchestrator_v2.py`

**Removed:**
- Manual JSON text areas for each chapter
- File upload widgets for memory images
- Mentimeter URL inputs
- Roman numeral/months text fields (Jahresr√ºckblick specific)
- Google Gem link references

**Added:**
- Gemini AI integration functions
- Automatic content generation pipeline
- Single transcript input field
- Progress tracking for generation
- Content preview tabs
- Generic video title/URL inputs

**Example of key change:**
```python
# V1: Manual input
json_memory = st.text_area("Memory JSON", height=150)

# V2: Automatic generation
if st.button("Generate All Content"):
    memory_prompts = generate_memory_prompts(transcript, model_choice)
    h5p_list, files = utils_image_gen.generate_memory_assets(memory_prompts, ...)
```

---

### `booklet_generator_iframe.py` ‚Üí `booklet_generator_v2.py`

**Removed:**
- `create_hardcoded_introduction()` function
- `create_mentimeter_page()` function
- `create_iframe_page()` function
- Hardcoded Jahresr√ºckblick text and structure
- Roman numerals, months parameters

**Added:**
- `create_custom_introduction(intro_data)` - generic introduction builder
- Flexible chapter processing based on type
- Dynamic cover image handling

**Example of key change:**
```python
# V1: Fixed structure
def create_hardcoded_introduction(roman_number: str):
    intro_html = f"""<h2>Willkommen zum Jahresr√ºckblick 2025, Teil {roman_number}</h2>
    <p>Gemeinsam blicken wir zur√ºck auf bewegende..."""

# V2: Dynamic structure
def create_custom_introduction(intro_data: dict):
    """
    intro_data from AI:
    - title: generated from content
    - welcome_text: specific to video
    - learning_objectives: extracted from transcript
    - workflow: based on actual chapters
    """
```

---

### `utils_booklet_iframe.py`

**Changes**: Minimal - mostly unchanged
- Same image compression logic
- Same H5P mapping utilities
- Same packaging functions

**Why?**: These are low-level utilities that work regardless of content source

---

### `utils_image_gen.py`

**Changes**: Minimal enhancements
- Better error handling
- More flexible parameter passing
- No structural changes to image generation logic

**Why?**: Image generation core algorithm is already generic

---

## New Files Added

### `cli_generator.py`
- Command-line interface for automation
- Useful for batch processing
- No Streamlit dependency

### `example_transcript.txt`
- Example input for testing
- Shows expected format

### `QUICKSTART.md`
- User-friendly guide
- Step-by-step instructions

### `.env.example`
- Configuration template
- Shows required environment variables

---

## Configuration Changes

### V1: Multiple specific parameters
```python
roman_number = st.text_input("Roman Numeral (e.g. II, III)")
months_text = st.text_input("Months Text (e.g. M√§rz-April)")
menti_url_6 = st.text_input("Reflexion URL (Step 6)")
menti_url_7 = st.text_input("Results URL (Step 7)")
```

### V2: Generic parameters
```python
video_title = st.text_input("Video Title")
video_url = st.text_input("Video URL (iframe embeddable)")
transcript = st.text_area("Video Transcript")
model_choice = st.selectbox("Gemini Model")
```

---

## API Integration

### V1: No AI integration
- Manual content creation
- External Google Gem dependency
- Human effort for each chapter

### V2: Gemini AI Integration
```python
import google.generativeai as genai

genai.configure(api_key=GEMINI_API_KEY)

def generate_intro_content(transcript, ...):
    model = genai.GenerativeModel(model_name)
    response = model.generate_content(prompt)
    return json.loads(response.text)
```

**Setup required:**
```bash
# Install new dependency
pip install google-generativeai

# Add to .env
GEMINI_API_KEY=your_key_here
```

---

## Memory Game Logic Changes

### V1: Fixed behavior
```python
"behaviour": {
    "useGrid": False, 
    "allowRetry": False,
    "numCardsToUse": 4  # <--- HARDCODED
}
```

### V2: Dynamic behavior
```python
"behaviour": {
    "useGrid": False, 
    "allowRetry": False,
    "numCardsToUse": len(cards_h5p) * 2  # <--- USES ALL GENERATED CARDS
}
```

---

## Quiz Pool Size

### V1: Hardcoded pool
```python
# In create_question_set for Quiz type
forced_pool_size=5  # Always 5 questions shown from pool
```

### V2: Configurable pool
```python
# Can be adjusted based on content
pool_size = min(forced_pool_size, len(questions_h5p))
# Default: 5 questions shown from 10 generated
```

---

## Step-by-Step Migration

### For Developers

1. **Install new dependencies**
   ```bash
   pip install google-generativeai python-dotenv
   ```

2. **Set up Gemini API**
   ```bash
   cp .env.example .env
   # Add your API key to .env
   ```

3. **Update imports**
   ```python
   # Old
   import booklet_generator_iframe as booklet_generator
   
   # New
   import booklet_generator_v2 as booklet_generator
   ```

4. **Replace manual input collection**
   ```python
   # Old: Manual JSON inputs
   json_memory = st.text_area("Memory JSON")
   json_video = st.text_area("Video JSON")
   
   # New: Single transcript input
   transcript = st.text_area("Video Transcript")
   # Generate all content with AI
   ```

5. **Update generation logic**
   ```python
   # Old: Parse manual JSONs
   parsed_data_list = []
   for raw_text in raw_inputs:
       data = json.loads(raw_text)
       parsed_data_list.append(data)
   
   # New: Generate from transcript
   intro = generate_intro_content(transcript, ...)
   memory = generate_memory_prompts(transcript, ...)
   summary = generate_video_summary(transcript, ...)
   # etc.
   ```

### For End Users

1. **Prepare your transcript**
   - Copy video transcript to text file
   - Ensure UTF-8 encoding
   - Minimum 1000 words recommended

2. **Get video embed URL**
   - Not: `youtube.com/watch?v=...`
   - Use: `youtube.com/embed/...`

3. **Run new interface**
   ```bash
   streamlit run orchestrator_v2.py
   ```

4. **Input and generate**
   - Paste transcript
   - Enter video URL and title
   - Click generate
   - Download H5P package

---

## Backward Compatibility

### Can I still use V1?
Yes, but not recommended. V1 remains in the repository but:
- Requires manual JSON creation
- Depends on Google Gem (external)
- Limited to Jahresr√ºckblick format
- More time-consuming

### Should I migrate?
**Yes, if you:**
- Want to automate content creation
- Need to process many videos
- Want flexibility beyond Jahresr√ºckblick
- Don't want to manually create JSONs

**Maybe not, if you:**
- Have very specific custom requirements not met by AI
- Need absolute control over every detail
- Already have a working V1 pipeline

---

## Performance Comparison

| Aspect | V1 | V2 |
|--------|----|----|
| Time to create content | 60-90 min | 3-5 min |
| Manual steps | ~15 | 3 |
| External tools needed | Google Gem, Mentimeter | None |
| Image sourcing | Manual upload | Automatic |
| Flexibility | Low (Jahresr√ºckblick only) | High (any topic) |
| Scalability | Poor (manual work) | Excellent (automated) |

---

## Common Migration Issues

### Issue 1: "GEMINI_API_KEY not found"
**Solution:**
```bash
# Create .env file
cp .env.example .env
# Edit and add your key
nano .env
```

### Issue 2: "Module 'google.generativeai' not found"
**Solution:**
```bash
pip install google-generativeai
```

### Issue 3: "Template not found"
**Solution:**
- Ensure `templates/template.zip` exists
- Copy from V1 if needed
- Template structure hasn't changed

### Issue 4: Generated content quality issues
**Solution:**
- Try different Gemini models (`gemini-1.5-pro` for quality)
- Provide longer, more detailed transcripts
- Adjust prompts in `orchestrator_v2.py`

---

## Future Enhancements

Possible additions to V2:
- [ ] Multi-language support (beyond German)
- [ ] Custom prompt templates
- [ ] More chapter types (e.g., flashcards, timeline)
- [ ] Batch processing UI
- [ ] Content editing/refinement interface
- [ ] Alternative AI providers (Claude, GPT-4)
- [ ] Export to other formats (SCORM, xAPI)

---

## Support

**For V1 issues**: Check original documentation
**For V2 issues**: See README.md and QUICKSTART.md
**For migration help**: Open GitHub issue with "migration" tag

---

**Last Updated**: December 2024  
**Migration Status**: V2 is production-ready
